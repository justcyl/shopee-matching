{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>posting_id</th>\n",
       "      <th>image</th>\n",
       "      <th>image_phash</th>\n",
       "      <th>title</th>\n",
       "      <th>label_group</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_129225211</td>\n",
       "      <td>../input/train_images/0000a68812bc7e98c42888df...</td>\n",
       "      <td>94974f937d4c2433</td>\n",
       "      <td>Paper Bag Victoria Secret</td>\n",
       "      <td>249114794</td>\n",
       "      <td>train_129225211 train_2278313361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_3386243561</td>\n",
       "      <td>../input/train_images/00039780dfc94d01db8676fe...</td>\n",
       "      <td>af3f9460c2838f0f</td>\n",
       "      <td>Double Tape 3M VHB 12 mm x 4,5 m ORIGINAL / DO...</td>\n",
       "      <td>2937985045</td>\n",
       "      <td>train_3386243561 train_3423213080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_2288590299</td>\n",
       "      <td>../input/train_images/000a190fdd715a2a36faed16...</td>\n",
       "      <td>b94cb00ed3e50f78</td>\n",
       "      <td>Maling TTS Canned Pork Luncheon Meat 397 gr</td>\n",
       "      <td>2395904891</td>\n",
       "      <td>train_2288590299 train_3803689425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_2406599165</td>\n",
       "      <td>../input/train_images/00117e4fc239b1b641ff0834...</td>\n",
       "      <td>8514fc58eafea283</td>\n",
       "      <td>Daster Batik Lengan pendek - Motif Acak / Camp...</td>\n",
       "      <td>4093212188</td>\n",
       "      <td>train_2406599165 train_3342059966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_3369186413</td>\n",
       "      <td>../input/train_images/00136d1cf4edede0203f32f0...</td>\n",
       "      <td>a6f319f924ad708c</td>\n",
       "      <td>Nescafe \\xc3\\x89clair Latte 220ml</td>\n",
       "      <td>3648931069</td>\n",
       "      <td>train_3369186413 train_921438619</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         posting_id                                              image  \\\n",
       "0   train_129225211  ../input/train_images/0000a68812bc7e98c42888df...   \n",
       "1  train_3386243561  ../input/train_images/00039780dfc94d01db8676fe...   \n",
       "2  train_2288590299  ../input/train_images/000a190fdd715a2a36faed16...   \n",
       "3  train_2406599165  ../input/train_images/00117e4fc239b1b641ff0834...   \n",
       "4  train_3369186413  ../input/train_images/00136d1cf4edede0203f32f0...   \n",
       "\n",
       "        image_phash                                              title  \\\n",
       "0  94974f937d4c2433                          Paper Bag Victoria Secret   \n",
       "1  af3f9460c2838f0f  Double Tape 3M VHB 12 mm x 4,5 m ORIGINAL / DO...   \n",
       "2  b94cb00ed3e50f78        Maling TTS Canned Pork Luncheon Meat 397 gr   \n",
       "3  8514fc58eafea283  Daster Batik Lengan pendek - Motif Acak / Camp...   \n",
       "4  a6f319f924ad708c                  Nescafe \\xc3\\x89clair Latte 220ml   \n",
       "\n",
       "   label_group                             target  \n",
       "0    249114794   train_129225211 train_2278313361  \n",
       "1   2937985045  train_3386243561 train_3423213080  \n",
       "2   2395904891  train_2288590299 train_3803689425  \n",
       "3   4093212188  train_2406599165 train_3342059966  \n",
       "4   3648931069   train_3369186413 train_921438619  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "COMPUTE_CV = True\n",
    "import pandas as pd\n",
    "\n",
    "# DATA_PATH = \"../input/shopee-product-matching/\"\n",
    "DATA_PATH = \"../input/\"\n",
    "\n",
    "\n",
    "if COMPUTE_CV == False:\n",
    "    train = pd.read_csv(DATA_PATH + \"test.csv\")\n",
    "    train[\"image\"] = DATA_PATH + \"test_images/\" + train[\"image\"]\n",
    "else:\n",
    "    train = pd.read_csv(DATA_PATH + \"train.csv\")\n",
    "    train[\"target\"] = train.label_group.map(\n",
    "        train.groupby(\"label_group\").posting_id.agg(\"unique\").to_dict()\n",
    "    )\n",
    "    train[\"target\"] = train[\"target\"].apply(lambda x: \" \".join(x))\n",
    "    train[\"image\"] = DATA_PATH + \"train_images/\" + train[\"image\"]\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "You should set CFG.CLASSES =  11014\n",
      "Building Model Backbone for ../input/shopee-models/paraphrase-xlm-r-multilingual-v1 model\n",
      "lr_start\n",
      "------------------------------\n",
      "Parameter Group 0 : 7.5e-06\n",
      "Parameter Group 1 : 1.5e-05\n",
      "Parameter Group 2 : 1.5e-05\n",
      "Parameter Group 3 : 1.5e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch: 1:   0%|                                                   | 0/2140 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch: 1:   0%|                | 1/2140 [00:00<33:08,  1.08it/s, loss=26.842501, LR=7.5e-6]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch: 1:   0%|                | 2/2140 [00:01<18:45,  1.90it/s, loss=26.712605, LR=7.5e-6]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch: 1:   0%|                | 3/2140 [00:01<14:24,  2.47it/s, loss=26.717801, LR=7.5e-6]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch: 1:   0%|                | 4/2140 [00:01<12:04,  2.95it/s, loss=26.754031, LR=7.5e-6]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch: 1:   0%|                | 6/2140 [00:02<09:45,  3.64it/s, loss=26.759616, LR=7.5e-6]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch: 1:   0%|                | 7/2140 [00:02<09:02,  3.93it/s, loss=26.822780, LR=7.5e-6]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch: 1:   0%|                | 8/2140 [00:02<08:20,  4.26it/s, loss=26.835511, LR=7.5e-6]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch: 1:   0%|                | 9/2140 [00:02<08:00,  4.43it/s, loss=26.833443, LR=7.5e-6]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch: 1:   0%|               | 10/2140 [00:02<07:53,  4.49it/s, loss=26.824944, LR=7.5e-6]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch: 1:   1%|               | 11/2140 [00:03<07:44,  4.59it/s, loss=26.812016, LR=7.5e-6]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch: 1:   1%|               | 12/2140 [00:03<07:31,  4.71it/s, loss=26.800892, LR=7.5e-6]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch: 1:   1%|               | 13/2140 [00:03<07:25,  4.78it/s, loss=26.791996, LR=7.5e-6]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch: 1:   1%|               | 15/2140 [00:03<07:24,  4.78it/s, loss=26.817740, LR=7.5e-6]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch: 1:   1%|               | 16/2140 [00:04<07:20,  4.82it/s, loss=26.816053, LR=7.5e-6]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch: 1:   1%|               | 17/2140 [00:04<07:16,  4.86it/s, loss=26.811239, LR=7.5e-6]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch: 1:   1%|▏              | 18/2140 [00:04<07:12,  4.90it/s, loss=26.793622, LR=7.5e-6]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch: 1:   1%|▏              | 20/2140 [00:04<07:01,  5.03it/s, loss=26.803890, LR=7.5e-6]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch: 1:   1%|▏              | 21/2140 [00:05<06:58,  5.06it/s, loss=26.798052, LR=7.5e-6]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch: 1:   1%|▏              | 21/2140 [00:05<08:51,  3.99it/s, loss=26.798052, LR=7.5e-6]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/cyl/wslwork/shopee-matching/source/input.ipynb Cell 2\u001b[0m line \u001b[0;36m6\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/cyl/wslwork/shopee-matching/source/input.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mxlm_v1_arcface\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/cyl/wslwork/shopee-matching/source/input.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# train = xlm_v1_arcface.eval(\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/cyl/wslwork/shopee-matching/source/input.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m#     train\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/cyl/wslwork/shopee-matching/source/input.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m# )\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/cyl/wslwork/shopee-matching/source/input.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m train \u001b[39m=\u001b[39m xlm_v1_arcface\u001b[39m.\u001b[39;49mtrain(\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/cyl/wslwork/shopee-matching/source/input.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m     train\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/cyl/wslwork/shopee-matching/source/input.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m )\n",
      "File \u001b[0;32m~/wslwork/shopee-matching/source/xlm_v1_arcface.py:698\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(df, destination, threshold)\u001b[0m\n\u001b[1;32m    694\u001b[0m train_df[\u001b[39m\"\u001b[39m\u001b[39mlabel_group\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m labelencoder\u001b[39m.\u001b[39mfit_transform(train_df[\u001b[39m\"\u001b[39m\u001b[39mlabel_group\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m    696\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mYou should set CFG.CLASSES = \u001b[39m\u001b[39m\"\u001b[39m, train_df[\u001b[39m\"\u001b[39m\u001b[39mlabel_group\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mnunique())\n\u001b[0;32m--> 698\u001b[0m run_training(train_df, valid_df, test_df, destination, threshold)\n",
      "File \u001b[0;32m~/wslwork/shopee-matching/source/xlm_v1_arcface.py:633\u001b[0m, in \u001b[0;36mrun_training\u001b[0;34m(train_df, valid_df, test_df, destination, threshold)\u001b[0m\n\u001b[1;32m    630\u001b[0m max_f1_valid \u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(CFG\u001b[39m.\u001b[39mepochs):\n\u001b[0;32m--> 633\u001b[0m     model, avg_loss_train \u001b[39m=\u001b[39m train_fn(\n\u001b[1;32m    634\u001b[0m         model,\n\u001b[1;32m    635\u001b[0m         train_dataloader,\n\u001b[1;32m    636\u001b[0m         optimizer,\n\u001b[1;32m    637\u001b[0m         scheduler,\n\u001b[1;32m    638\u001b[0m         CFG\u001b[39m.\u001b[39;49muse_sam,\n\u001b[1;32m    639\u001b[0m         CFG\u001b[39m.\u001b[39;49maccum_iter,\n\u001b[1;32m    640\u001b[0m         epoch,\n\u001b[1;32m    641\u001b[0m         CFG\u001b[39m.\u001b[39;49mdevice,\n\u001b[1;32m    642\u001b[0m         CFG\u001b[39m.\u001b[39;49muse_amp,\n\u001b[1;32m    643\u001b[0m     )\n\u001b[1;32m    645\u001b[0m     valid_embeddings \u001b[39m=\u001b[39m get_valid_embeddings(valid_df, \u001b[39m\"\u001b[39m\u001b[39mtitle\u001b[39m\u001b[39m\"\u001b[39m, model)\n\u001b[1;32m    646\u001b[0m     \u001b[39m# print(valid_embeddings.shape)\u001b[39;00m\n",
      "File \u001b[0;32m~/wslwork/shopee-matching/source/xlm_v1_arcface.py:492\u001b[0m, in \u001b[0;36mtrain_fn\u001b[0;34m(model, data_loader, optimizer, scheduler, use_sam, accum_iter, epoch, device, use_amp)\u001b[0m\n\u001b[1;32m    490\u001b[0m loss\u001b[39m.\u001b[39mmean()\u001b[39m.\u001b[39mbackward()\n\u001b[1;32m    491\u001b[0m optimizer\u001b[39m.\u001b[39mfirst_step(zero_grad\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m--> 492\u001b[0m fin_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39;49mitem()\n\u001b[1;32m    493\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mamp\u001b[39m.\u001b[39mautocast():\n\u001b[1;32m    494\u001b[0m     _, loss_second \u001b[39m=\u001b[39m model(texts, labels)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import xlm_v1_arcface\n",
    "\n",
    "# train = xlm_v1_arcface.eval(\n",
    "#     train\n",
    "# )\n",
    "train = xlm_v1_arcface.train(\n",
    "    train\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Model Backbone for eca_nfnet_l0 model\n",
      "2304 512\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2313bfa037e2460aab3a583c92c9e84d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<built-in method size of Tensor object at 0x7f1a2f0ca4d0>\n",
      "<built-in method size of Tensor object at 0x7f1b7e4ba610>\n",
      "Our image embeddings shape is (16, 11014)\n",
      "got embeddings! threshold=0.36\n",
      "image embeddings shape (16, 11014)\n",
      "Finding similar by cosine KNN..., len of train: 16, KNN=55\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "n_neighbors must be <= number of samples in index",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/cyl/wslwork/shopee-matching/source/input.ipynb Cell 4\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/cyl/wslwork/shopee-matching/source/input.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39meca_nfnet_l0_arc_face\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/cyl/wslwork/shopee-matching/source/input.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m train \u001b[39m=\u001b[39m eca_nfnet_l0_arc_face\u001b[39m.\u001b[39;49meval(\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/cyl/wslwork/shopee-matching/source/input.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m     train, destination\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39moof_nfnet_arcface\u001b[39;49m\u001b[39m\"\u001b[39;49m, threshold\u001b[39m=\u001b[39;49m\u001b[39m0.36\u001b[39;49m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/cyl/wslwork/shopee-matching/source/input.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m )\n",
      "File \u001b[0;32m~/wslwork/shopee-matching/source/eca_nfnet_l0_arc_face.py:478\u001b[0m, in \u001b[0;36meval\u001b[0;34m(train, destination, threshold)\u001b[0m\n\u001b[1;32m    474\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mimage embeddings shape\u001b[39m\u001b[39m\"\u001b[39m, imagefeat\u001b[39m.\u001b[39mshape)\n\u001b[1;32m    476\u001b[0m \u001b[39m# text_embeddings = text_embeddings.cuda()\u001b[39;00m\n\u001b[0;32m--> 478\u001b[0m train \u001b[39m=\u001b[39m get_KNN\u001b[39m.\u001b[39;49mget_valid_neighbors(\n\u001b[1;32m    479\u001b[0m     train, imagefeat, destination\u001b[39m=\u001b[39;49mdestination, threshold\u001b[39m=\u001b[39;49mthreshold\n\u001b[1;32m    480\u001b[0m )\n\u001b[1;32m    482\u001b[0m \u001b[39m# train = cos_search.search(\u001b[39;00m\n\u001b[1;32m    483\u001b[0m \u001b[39m#     train, imagefeat, destination=destination, threshold=threshold\u001b[39;00m\n\u001b[1;32m    484\u001b[0m \u001b[39m# )\u001b[39;00m\n\u001b[1;32m    485\u001b[0m \u001b[39mdel\u001b[39;00m imagefeat\n",
      "File \u001b[0;32m~/wslwork/shopee-matching/source/../input/utils/get_KNN.py:15\u001b[0m, in \u001b[0;36mget_valid_neighbors\u001b[0;34m(df, embeddings, destination, threshold, KNN)\u001b[0m\n\u001b[1;32m     13\u001b[0m model \u001b[39m=\u001b[39m cuml\u001b[39m.\u001b[39mNearestNeighbors(n_neighbors \u001b[39m=\u001b[39m KNN, metric \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mcosine\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     14\u001b[0m model\u001b[39m.\u001b[39mfit(embeddings)\n\u001b[0;32m---> 15\u001b[0m distances, indices \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mkneighbors(embeddings)\n\u001b[1;32m     17\u001b[0m predictions \u001b[39m=\u001b[39m []\n\u001b[1;32m     18\u001b[0m \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(embeddings\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]):\n",
      "File \u001b[0;32m~/miniconda3/envs/kaggle/lib/python3.10/site-packages/cuml/internals/api_decorators.py:190\u001b[0m, in \u001b[0;36m_make_decorator_function.<locals>.decorator_function.<locals>.decorator_closure.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    188\u001b[0m         ret \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    189\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 190\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    192\u001b[0m \u001b[39mreturn\u001b[39;00m cm\u001b[39m.\u001b[39mprocess_return(ret)\n",
      "File \u001b[0;32m~/miniconda3/envs/kaggle/lib/python3.10/site-packages/cuml/internals/api_decorators.py:393\u001b[0m, in \u001b[0;36menable_device_interop.<locals>.dispatch\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mdispatch_func\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    392\u001b[0m     func_name \u001b[39m=\u001b[39m gpu_func\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\n\u001b[0;32m--> 393\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_func(func_name, gpu_func, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    394\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    395\u001b[0m     \u001b[39mreturn\u001b[39;00m gpu_func(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/kaggle/lib/python3.10/site-packages/cuml/internals/api_decorators.py:190\u001b[0m, in \u001b[0;36m_make_decorator_function.<locals>.decorator_function.<locals>.decorator_closure.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    188\u001b[0m         ret \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    189\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 190\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    192\u001b[0m \u001b[39mreturn\u001b[39;00m cm\u001b[39m.\u001b[39mprocess_return(ret)\n",
      "File \u001b[0;32mbase.pyx:665\u001b[0m, in \u001b[0;36mcuml.internals.base.UniversalBase.dispatch_func\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mnearest_neighbors.pyx:535\u001b[0m, in \u001b[0;36mcuml.neighbors.nearest_neighbors.NearestNeighbors.kneighbors\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mnearest_neighbors.pyx:607\u001b[0m, in \u001b[0;36mcuml.neighbors.nearest_neighbors.NearestNeighbors._kneighbors_internal\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: n_neighbors must be <= number of samples in index"
     ]
    }
   ],
   "source": [
    "import eca_nfnet_l0_arc_face\n",
    "\n",
    "train = eca_nfnet_l0_arc_face.eval(\n",
    "    train, destination=\"oof_nfnet_arcface\", threshold=0.36\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def combine_for_sub(row):\n",
    "    x=row.oof_xlm_arcface.split(' ') + row.oof_nfnet_arcface.split(' ')\n",
    "    # x = np.concatenate([row.oof_xlm_arcface, row.oof_nfnet_arcface])\n",
    "    return ' '.join( set(x) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()\n",
    "train['matches'] = train.apply(combine_for_sub,axis=1)\n",
    "train.to_csv(DATA_PATH+\"res.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9703171268253422\n"
     ]
    }
   ],
   "source": [
    "import eval_preds\n",
    "train['precision'],train['recall'],train['f1'] =  eval_preds.get_score(train['target'], train[\"matches\"])\n",
    "print(train.f1.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = eca_nfnet_l0_arc_face.eval(\n",
    "    train, destination=\"oof_nfnet_arcface\", threshold=0.36\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
