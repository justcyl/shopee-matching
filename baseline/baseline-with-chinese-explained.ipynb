{"cells":[{"cell_type":"code","execution_count":55,"metadata":{"ExecuteTime":{"end_time":"2021-03-18T09:59:13.247406Z","start_time":"2021-03-18T09:59:13.24369Z"},"execution":{"iopub.execute_input":"2023-11-04T18:48:14.585860Z","iopub.status.busy":"2023-11-04T18:48:14.584841Z","iopub.status.idle":"2023-11-04T18:48:14.589934Z","shell.execute_reply":"2023-11-04T18:48:14.589021Z","shell.execute_reply.started":"2023-11-04T18:48:14.585818Z"},"papermill":{"duration":0.054989,"end_time":"2021-03-25T13:08:48.825601","exception":false,"start_time":"2021-03-25T13:08:48.770612","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["# DATA_PATH = '../input/'\n","\n","# 注意填入你的路径\n","# DATA_PATH = './'\n","# DATA_PATH = '../input/shopee-product-matching/'\n","DATA_PATH = '../input/'\n","\n","# import psutil"]},{"cell_type":"markdown","metadata":{},"source":["### how to calculate $ F1 $ score\n","令$ a=TP $ , $ c=FP $ , $ d=FN $ <p>\n","$ F1=\\frac{(2*(a/(a+c))*(a/(a+d)))}{(a/(a+c)+a/(a+d))}=\\frac{(2*a)}{(a+c+a+d)} $<p>\n","其中$ n=a $ , $ len(row.target)=a+d $ , $ len(row[col])=a+c $ <p>\n","即 $ F1 $ 是精确率和召回率的调和平均数"]},{"cell_type":"code","execution_count":56,"metadata":{"ExecuteTime":{"end_time":"2021-03-18T09:59:14.869532Z","start_time":"2021-03-18T09:59:14.482759Z"},"execution":{"iopub.execute_input":"2023-11-04T18:48:14.591884Z","iopub.status.busy":"2023-11-04T18:48:14.591568Z","iopub.status.idle":"2023-11-04T18:48:14.601248Z","shell.execute_reply":"2023-11-04T18:48:14.600346Z","shell.execute_reply.started":"2023-11-04T18:48:14.591852Z"},"papermill":{"duration":0.273366,"end_time":"2021-03-25T13:08:49.119467","exception":false,"start_time":"2021-03-25T13:08:48.846101","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","import cv2, matplotlib.pyplot as plt\n","from tqdm import tqdm_notebook\n","import tqdm\n","import gc\n","\n","# import cudf, cuml, cupy\n","# from cuml.feature_extraction.text import TfidfVectorizer\n","# from cuml.neighbors import NearestNeighbors\n","\n","# 对于样本 row，根据表现分组 (P/N)row[col] 和实际分组 (T/F)row.target 计算 F1\n","def getMetric(col):\n","    def f1score(row):\n","        # 查找两个数组的交集 T and P \n","        n = len( np.intersect1d(row.target,row[col]) ) \n","        # row.target实际P, row[col]表现P,计算公式见上一个cell\n","        return 2*n / (len(row.target)+len(row[col]))\n","    return f1score"]},{"cell_type":"code","execution_count":57,"metadata":{"ExecuteTime":{"end_time":"2021-03-18T09:59:15.92512Z","start_time":"2021-03-18T09:59:15.308672Z"},"execution":{"iopub.execute_input":"2023-11-04T18:48:14.603407Z","iopub.status.busy":"2023-11-04T18:48:14.603026Z","iopub.status.idle":"2023-11-04T18:48:15.376209Z","shell.execute_reply":"2023-11-04T18:48:15.375061Z","shell.execute_reply.started":"2023-11-04T18:48:14.603382Z"},"papermill":{"duration":1.368221,"end_time":"2021-03-25T13:08:50.511327","exception":false,"start_time":"2021-03-25T13:08:49.143106","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["this submission notebook will compute CV score, but commit notebook will not\n","train shape is (16, 6)\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>posting_id</th>\n","      <th>image</th>\n","      <th>image_phash</th>\n","      <th>title</th>\n","      <th>label_group</th>\n","      <th>target</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2</th>\n","      <td>train_2288590299</td>\n","      <td>../input/train_images/000a190fdd715a2a36faed16...</td>\n","      <td>b94cb00ed3e50f78</td>\n","      <td>Maling TTS Canned Pork Luncheon Meat 397 gr</td>\n","      <td>2395904891</td>\n","      <td>[train_2288590299]</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>train_1598329973</td>\n","      <td>../input/train_images/001d7f5d9a2fac714f4d5f37...</td>\n","      <td>bec8d09693634b4b</td>\n","      <td>Atasan Rajut Wanita LISDIA SWEATER</td>\n","      <td>2462407944</td>\n","      <td>[train_1598329973]</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>train_4287573913</td>\n","      <td>../input/train_images/001f5580b058c6b8e3313219...</td>\n","      <td>dc85e1750687f932</td>\n","      <td>Charger VIZZ VZ-TC11 / batok charger vizz 1A O...</td>\n","      <td>1932232224</td>\n","      <td>[train_4287573913]</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>train_4196427721</td>\n","      <td>../input/train_images/002039aaf8618627a0442d5e...</td>\n","      <td>e98c873acc65946e</td>\n","      <td>Korek Kuping LED untuk balita CherryBabyKidsSh...</td>\n","      <td>349297863</td>\n","      <td>[train_4196427721]</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>train_2985955659</td>\n","      <td>../input/train_images/002f978c58a44a00aadfca71...</td>\n","      <td>bf38f0e083d7c710</td>\n","      <td>HnKfashion Sweater Hoodie WHO Printing BabyTer...</td>\n","      <td>3415582503</td>\n","      <td>[train_2985955659]</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["          posting_id                                              image  \\\n","2   train_2288590299  ../input/train_images/000a190fdd715a2a36faed16...   \n","10  train_1598329973  ../input/train_images/001d7f5d9a2fac714f4d5f37...   \n","14  train_4287573913  ../input/train_images/001f5580b058c6b8e3313219...   \n","15  train_4196427721  ../input/train_images/002039aaf8618627a0442d5e...   \n","18  train_2985955659  ../input/train_images/002f978c58a44a00aadfca71...   \n","\n","         image_phash                                              title  \\\n","2   b94cb00ed3e50f78        Maling TTS Canned Pork Luncheon Meat 397 gr   \n","10  bec8d09693634b4b                 Atasan Rajut Wanita LISDIA SWEATER   \n","14  dc85e1750687f932  Charger VIZZ VZ-TC11 / batok charger vizz 1A O...   \n","15  e98c873acc65946e  Korek Kuping LED untuk balita CherryBabyKidsSh...   \n","18  bf38f0e083d7c710  HnKfashion Sweater Hoodie WHO Printing BabyTer...   \n","\n","    label_group              target  \n","2    2395904891  [train_2288590299]  \n","10   2462407944  [train_1598329973]  \n","14   1932232224  [train_4287573913]  \n","15    349297863  [train_4196427721]  \n","18   3415582503  [train_2985955659]  "]},"execution_count":57,"metadata":{},"output_type":"execute_result"}],"source":["COMPUTE_CV = True\n","\n","test = pd.read_csv(DATA_PATH + 'test.csv')\n","if len(test)>3: COMPUTE_CV = False # 私榜提交test\n","else: print('this submission notebook will compute CV score, but commit notebook will not') # 公榜test，因为test.csv只有3行\n","\n","# COMPUTE_CV = False\n","\n","if COMPUTE_CV:\n","    train = pd.read_csv(DATA_PATH + 'train_min.csv')\n","    train['image'] = DATA_PATH + 'train_images/' + train['image']\n","    # 对tmp分组，并对每一组提取posting_id的集合\n","    tmp = train.groupby('label_group').posting_id.agg('unique').to_dict()\n","    # print(tmp)\n","    # 利用 tmp 将列出同一组的所有 posting_id\n","    # target 即是 训练集的正确分组\n","    train['target'] = train.label_group.map(tmp)\n","else:\n","    train = pd.read_csv(DATA_PATH + 'test.csv')\n","    train['image'] = DATA_PATH + 'test_images/' + train['image']\n","    \n","print('train shape is', train.shape )\n","train.head()"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.051016,"end_time":"2021-03-25T13:22:15.971324","exception":false,"start_time":"2021-03-25T13:22:15.920308","status":"completed"},"tags":[]},"source":["# title TFIDF"]},{"cell_type":"code","execution_count":58,"metadata":{"ExecuteTime":{"end_time":"2021-03-18T10:02:00.631468Z","start_time":"2021-03-18T10:01:59.851964Z"},"execution":{"iopub.execute_input":"2023-11-04T18:48:15.378372Z","iopub.status.busy":"2023-11-04T18:48:15.378040Z","iopub.status.idle":"2023-11-04T18:48:19.574251Z","shell.execute_reply":"2023-11-04T18:48:19.573437Z","shell.execute_reply.started":"2023-11-04T18:48:15.378345Z"},"papermill":{"duration":1.884816,"end_time":"2021-03-25T13:22:17.906637","exception":false,"start_time":"2021-03-25T13:22:16.021821","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["text embeddings shape (16, 141)\n"]}],"source":["from PIL import Image\n","\n","import torch\n","\n","import torchvision.models as models\n","import torchvision.transforms as transforms\n","import torchvision.datasets as datasets\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.autograd import Variable\n","from torch.utils.data.dataset import Dataset\n","\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","model = TfidfVectorizer(stop_words=None, binary=True, max_features=20250)\n","text_embeddings = model.fit_transform(train.title).toarray()\n","print('text embeddings shape',text_embeddings.shape)\n","\n","text_embeddings = torch.from_numpy(text_embeddings)\n","text_embeddings = text_embeddings.cuda()\n","del model\n","# preds = []\n","# CHUNK = 1024*4\n","\n","# print('Finding similar titles...')\n","# CTS = len(train)//CHUNK\n","# if len(train)%CHUNK!=0: CTS += 1\n","# CTS_index = 0\n","# for j in range( CTS ):\n","    \n","#     a = j*CHUNK\n","#     b = (j+1)*CHUNK\n","#     b = min(b,len(train))\n","#     print('chunk',a,'to',b)\n","    \n","#     # COSINE SIMILARITY DISTANCE\n","#     # cts = np.dot( text_embeddings, text_embeddings[a:b].T).T\n","#     cts = torch.matmul(text_embeddings, text_embeddings[a:b].T).T\n","#     cts = cts.data.cpu().numpy()\n","#     print(cts.shape)\n","#     for k in range(b-a):\n","#         # IDX = np.where(cts[k,]>0.7)[0]\n","#         IDX = np.where(cts[k,]>0.7)[0]\n","#         o = train.iloc[IDX].posting_id.values\n","#         preds.append(o)\n","#         CTS_index += 1\n","# # del model, text_embeddings\n","\n","# train['oof_text'] = preds\n","# # 仅考虑 TFIDF 的成绩\n","# if COMPUTE_CV:\n","#     train['f1'] = train.apply(getMetric('oof_text'),axis=1)\n","#     print('CV score for baseline =',train.f1.mean())\n","    \n","    \n","# 0.6137154152579091 0.7\n","# 0.6507316994356058 0.6"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.026403,"end_time":"2021-03-25T13:08:50.569269","exception":false,"start_time":"2021-03-25T13:08:50.542866","status":"completed"},"tags":[]},"source":["# image hash"]},{"cell_type":"code","execution_count":59,"metadata":{"ExecuteTime":{"end_time":"2021-03-18T09:59:19.569052Z","start_time":"2021-03-18T09:59:18.284395Z"},"execution":{"iopub.execute_input":"2023-11-04T18:48:19.575718Z","iopub.status.busy":"2023-11-04T18:48:19.575363Z","iopub.status.idle":"2023-11-04T18:48:19.580083Z","shell.execute_reply":"2023-11-04T18:48:19.579053Z","shell.execute_reply.started":"2023-11-04T18:48:19.575691Z"},"papermill":{"duration":3.527475,"end_time":"2021-03-25T13:08:54.118520","exception":false,"start_time":"2021-03-25T13:08:50.591045","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["# # 列出hash相同的所有id\n","# tmp = train.groupby('image_phash').posting_id.agg('unique').to_dict()\n","# train['oof_hash'] = train.image_phash.map(tmp)"]},{"cell_type":"code","execution_count":60,"metadata":{"ExecuteTime":{"end_time":"2021-03-18T09:59:21.98207Z","start_time":"2021-03-18T09:59:20.62671Z"},"execution":{"iopub.execute_input":"2023-11-04T18:48:19.582562Z","iopub.status.busy":"2023-11-04T18:48:19.582163Z","iopub.status.idle":"2023-11-04T18:48:19.588726Z","shell.execute_reply":"2023-11-04T18:48:19.587690Z","shell.execute_reply.started":"2023-11-04T18:48:19.582530Z"},"papermill":{"duration":3.064329,"end_time":"2021-03-25T13:08:57.206295","exception":false,"start_time":"2021-03-25T13:08:54.141966","status":"completed"},"scrolled":true,"tags":[],"trusted":true},"outputs":[],"source":["# # 精确率“几乎” 100%的策略：图像 hash 相同的一组。并计算分数\n","# # 数据可能有噪声，所以无法保证100%精确率，另外此策略召唤率较低\n","# if COMPUTE_CV:\n","#     train['f1'] = train.apply(getMetric('oof_hash'),axis=1)\n","#     print('CV score for baseline =',train.f1.mean())"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.02268,"end_time":"2021-03-25T13:08:57.560970","exception":false,"start_time":"2021-03-25T13:08:57.538290","status":"completed"},"tags":[]},"source":["# image CNN"]},{"cell_type":"code","execution_count":61,"metadata":{"ExecuteTime":{"end_time":"2021-03-18T09:59:24.147684Z","start_time":"2021-03-18T09:59:23.6933Z"},"execution":{"iopub.execute_input":"2023-11-04T18:48:19.590086Z","iopub.status.busy":"2023-11-04T18:48:19.589776Z","iopub.status.idle":"2023-11-04T18:48:19.601087Z","shell.execute_reply":"2023-11-04T18:48:19.600246Z","shell.execute_reply.started":"2023-11-04T18:48:19.590064Z"},"papermill":{"duration":1.953016,"end_time":"2021-03-25T13:08:59.536041","exception":false,"start_time":"2021-03-25T13:08:57.583025","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["\n","\n","class ShopeeImageDataset(Dataset):\n","    def __init__(self, img_path, transform):\n","        self.img_path = img_path\n","        self.transform = transform\n","        \n","    def __getitem__(self, index):\n","        img = Image.open(self.img_path[index]).convert('RGB')\n","        img = self.transform(img)\n","        return img\n","    \n","    def __len__(self):\n","        return len(self.img_path)"]},{"cell_type":"code","execution_count":62,"metadata":{"ExecuteTime":{"end_time":"2021-03-18T09:59:25.6502Z","start_time":"2021-03-18T09:59:25.64389Z"},"execution":{"iopub.execute_input":"2023-11-04T18:48:19.602884Z","iopub.status.busy":"2023-11-04T18:48:19.602305Z","iopub.status.idle":"2023-11-04T18:48:19.610969Z","shell.execute_reply":"2023-11-04T18:48:19.610068Z","shell.execute_reply.started":"2023-11-04T18:48:19.602852Z"},"papermill":{"duration":0.034909,"end_time":"2021-03-25T13:08:59.595438","exception":false,"start_time":"2021-03-25T13:08:59.560529","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["# 图像预处理 dataset 和 DataLoader\n","imagedataset = ShopeeImageDataset(\n","    train['image'].values,\n","    transforms.Compose([\n","        transforms.Resize((512, 512)),\n","        transforms.ToTensor(),\n","        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) # resnet 18处理前需要按此Normalize\n","]))\n","    \n","imageloader = torch.utils.data.DataLoader(\n","    imagedataset,\n","    batch_size=40, shuffle=False, num_workers=2\n",")"]},{"cell_type":"code","execution_count":63,"metadata":{"ExecuteTime":{"end_time":"2021-03-18T09:59:27.08827Z","start_time":"2021-03-18T09:59:27.083495Z"},"execution":{"iopub.execute_input":"2023-11-04T18:48:19.612294Z","iopub.status.busy":"2023-11-04T18:48:19.612003Z","iopub.status.idle":"2023-11-04T18:48:19.620173Z","shell.execute_reply":"2023-11-04T18:48:19.619257Z","shell.execute_reply.started":"2023-11-04T18:48:19.612261Z"},"papermill":{"duration":0.034326,"end_time":"2021-03-25T13:08:59.653401","exception":false,"start_time":"2021-03-25T13:08:59.619075","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["class ShopeeImageEmbeddingNet(nn.Module):\n","    def __init__(self):\n","        super(ShopeeImageEmbeddingNet, self).__init__()\n","              \n","        model = models.resnet18(pretrained=False)\n","        # 作者评论： 在检索任务中，最大池化优于平均池化。\n","        model.avgpool = nn.AdaptiveMaxPool2d(output_size=(1, 1)) # 最后一层令大小为1*1，参数自适应\n","        model = nn.Sequential(*list(model.children())[:-1]) # remove the last fully-connected layer\n","        model.eval() # 不再改变权重\n","        self.model = model\n","        \n","    def forward(self, img):        \n","        out = self.model(img)\n","        return out"]},{"cell_type":"code","execution_count":64,"metadata":{"execution":{"iopub.execute_input":"2023-11-04T18:48:19.621688Z","iopub.status.busy":"2023-11-04T18:48:19.621367Z","iopub.status.idle":"2023-11-04T18:48:19.628625Z","shell.execute_reply":"2023-11-04T18:48:19.627891Z","shell.execute_reply.started":"2023-11-04T18:48:19.621656Z"},"papermill":{"duration":5.948022,"end_time":"2021-03-25T13:09:05.625168","exception":false,"start_time":"2021-03-25T13:08:59.677146","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["# 下载resnet18预训练模型\n","# !mkdir -p /root/.cache/torch/hub/checkpoints/\n","# !cp ../input/resnet18-f37072fd/resnet18-f37072fd.pth /root/.cache/torch/hub/checkpoints/"]},{"cell_type":"code","execution_count":65,"metadata":{"ExecuteTime":{"end_time":"2021-03-18T10:01:20.420477Z","start_time":"2021-03-18T09:59:28.809744Z"},"execution":{"iopub.execute_input":"2023-11-04T18:48:19.630121Z","iopub.status.busy":"2023-11-04T18:48:19.629800Z"},"papermill":{"duration":741.508879,"end_time":"2021-03-25T13:21:27.159001","exception":false,"start_time":"2021-03-25T13:09:05.650122","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/cyl/miniconda3/envs/kaggle/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/home/cyl/miniconda3/envs/kaggle/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n","  warnings.warn(msg)\n","/tmp/ipykernel_4957/1849022496.py:8: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n","Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n","  for data in tqdm_notebook(imageloader):\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d1456c73c1134fc5b1ced94d43da937d","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"}],"source":["DEVICE = 'cuda'\n","\n","imgmodel = ShopeeImageEmbeddingNet()\n","imgmodel = imgmodel.to(DEVICE)\n","\n","imagefeat = []\n","with torch.no_grad():\n","    for data in tqdm_notebook(imageloader):\n","        data = data.to(DEVICE)\n","        feat = imgmodel(data)\n","        feat = feat.reshape(feat.shape[0], feat.shape[1])\n","        feat = feat.data.cpu().numpy()\n","        \n","        imagefeat.append(feat)"]},{"cell_type":"markdown","metadata":{},"source":["resnet18 以批次为单位训练\n","imagefeat 记录每一批次的结果，每一批次结果为一个维度为 (批大小)*512(通道) 的向量\n","接下来需要把所以批次合并，形成若干个512维向量，每个向量对应一张照片"]},{"cell_type":"code","execution_count":66,"metadata":{"ExecuteTime":{"end_time":"2021-03-18T10:01:43.818543Z","start_time":"2021-03-18T10:01:43.401624Z"},"papermill":{"duration":1.103212,"end_time":"2021-03-25T13:21:28.287599","exception":false,"start_time":"2021-03-25T13:21:27.184387","status":"completed"},"scrolled":true,"tags":[],"trusted":true},"outputs":[],"source":["from sklearn.preprocessing import normalize\n","\n","# l2 norm to kill all the sim in 0-1\n","imagefeat = np.vstack(imagefeat) \n","imagefeat = normalize(imagefeat) # 对每一个嵌入向量归一化 axis=1:normalize each sample"]},{"cell_type":"code","execution_count":67,"metadata":{"papermill":{"duration":0.044928,"end_time":"2021-03-25T13:21:28.358366","exception":false,"start_time":"2021-03-25T13:21:28.313438","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["imagefeat = torch.from_numpy(imagefeat)\n","imagefeat = imagefeat.cuda()"]},{"cell_type":"code","execution_count":68,"metadata":{"ExecuteTime":{"end_time":"2021-03-18T10:01:54.771453Z","start_time":"2021-03-18T10:01:44.50243Z"},"papermill":{"duration":44.036217,"end_time":"2021-03-25T13:22:12.419798","exception":false,"start_time":"2021-03-25T13:21:28.383581","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Finding similar images...\n","chunk 0 to 16\n"]}],"source":["preds = []\n","CHUNK = 1024*4\n","\n","\n","print('Finding similar images...')\n","CTS = len(imagefeat)//CHUNK\n","if len(imagefeat)%CHUNK!=0: CTS += 1\n","for j in range( CTS ):\n","    \n","    a = j*CHUNK\n","    b = (j+1)*CHUNK\n","    b = min(b, len(imagefeat))\n","    print('chunk',a,'to',b) # 对a到b的每一个数据计算它到其他数据的距离\n","    cts = torch.matmul(text_embeddings, text_embeddings[a:b].T).T\n","    cts = cts.data.cpu().numpy()\n","    distances = torch.matmul(imagefeat, imagefeat[a:b].T).T # 点乘计算余弦相似度，注意最后的转置\n","    distances = distances.data.cpu().numpy()\n","    # distances = np.dot(imagefeat[a:b,], imagefeat.T)\n","    \n","    for k in range(b-a):\n","        # IDX = cupy.where(distances[k,]>0.95)[0]\n","        similarity_score = (distances[k] / 0.84) ** 6 + (cts[k] / 0.84) ** 6\n","        IDX = np.where(similarity_score>1)[0][:] # 注意这个“距离”是余弦，角度越小余弦值越大，所以是越大越相似\n","        o = train.iloc[IDX].posting_id.values\n","#       o = train.iloc[cupy.asnumpy(IDX)].posting_id.values\n","        preds.append(o)\n","\n","del imagefeat, imgmodel,text_embeddings"]},{"cell_type":"code","execution_count":69,"metadata":{"ExecuteTime":{"end_time":"2021-03-18T10:01:58.132852Z","start_time":"2021-03-18T10:01:56.678412Z"},"papermill":{"duration":3.420182,"end_time":"2021-03-25T13:22:15.869633","exception":false,"start_time":"2021-03-25T13:22:12.449451","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["CV score for baseline = 1.0\n"]}],"source":["train['oof_cnn'] = preds\n","# 仅考虑 resnet 的成绩\n","if COMPUTE_CV:\n","    train['f1'] = train.apply(getMetric('oof_cnn'),axis=1)\n","    print('CV score for baseline =',train.f1.mean())\n","    \n","# 0.6527899883424048 0.95\n","# 0.6686372611222741 0.94\n","# 0.6762305764407363 0.93"]},{"cell_type":"code","execution_count":70,"metadata":{"ExecuteTime":{"end_time":"2021-03-18T10:06:04.931476Z","start_time":"2021-03-18T10:06:04.925838Z"},"papermill":{"duration":0.048906,"end_time":"2021-03-25T13:23:33.386521","exception":false,"start_time":"2021-03-25T13:23:33.337615","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["# 对每一个数据，取[tfidf匹配结果,cnn匹配结果,hash匹配结果]的交集\n","def combine_for_sub(row):\n","    x = np.concatenate([row.oof_text,row.oof_cnn, row.oof_hash])\n","    return ' '.join( np.unique(x) )\n","\n","def combine_for_cv(row):\n","    x = np.concatenate([row.oof_text,row.oof_cnn, row.oof_hash])\n","    return np.unique(x)"]},{"cell_type":"code","execution_count":71,"metadata":{"ExecuteTime":{"end_time":"2021-03-18T10:06:09.759812Z","start_time":"2021-03-18T10:06:05.955972Z"},"papermill":{"duration":10.942258,"end_time":"2021-03-25T13:23:44.365719","exception":false,"start_time":"2021-03-25T13:23:33.423461","status":"completed"},"tags":[],"trusted":true},"outputs":[{"data":{"text/plain":["2     [train_2288590299]\n","10    [train_1598329973]\n","14    [train_4287573913]\n","15    [train_4196427721]\n","18    [train_2985955659]\n","Name: matches, dtype: object"]},"execution_count":71,"metadata":{},"output_type":"execute_result"}],"source":["# if COMPUTE_CV:\n","#     tmp = train.groupby('label_group').posting_id.agg('unique').to_dict()\n","#     train['target'] = train.label_group.map(tmp)\n","#     train['oof'] = train.apply(combine_for_cv,axis=1)\n","#     train['f1'] = train.apply(getMetric('oof'),axis=1)\n","#     print('CV Score =', train.f1.mean() )\n","\n","# train['matches'] = train.apply(combine_for_sub,axis=1)\n","train['matches']=train['oof_cnn'] \n","train['matches'].head()"]},{"cell_type":"code","execution_count":72,"metadata":{"ExecuteTime":{"end_time":"2021-03-18T10:06:12.385916Z","start_time":"2021-03-18T10:06:12.180234Z"},"papermill":{"duration":0.453544,"end_time":"2021-03-25T13:23:44.864187","exception":false,"start_time":"2021-03-25T13:23:44.410643","status":"completed"},"tags":[],"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>posting_id</th>\n","      <th>matches</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>train_2288590299</td>\n","      <td>['train_2288590299']</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>train_1598329973</td>\n","      <td>['train_1598329973']</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>train_4287573913</td>\n","      <td>['train_4287573913']</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>train_4196427721</td>\n","      <td>['train_4196427721']</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>train_2985955659</td>\n","      <td>['train_2985955659']</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["         posting_id               matches\n","0  train_2288590299  ['train_2288590299']\n","1  train_1598329973  ['train_1598329973']\n","2  train_4287573913  ['train_4287573913']\n","3  train_4196427721  ['train_4196427721']\n","4  train_2985955659  ['train_2985955659']"]},"execution_count":72,"metadata":{},"output_type":"execute_result"}],"source":["train[['posting_id','matches']].to_csv('submission.csv',index=False)\n","sub = pd.read_csv('submission.csv')\n","sub.head()"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
